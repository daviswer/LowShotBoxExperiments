{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "from IPython import display\n",
    "from copy import deepcopy\n",
    "from skimage.transform import resize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Important Values\n",
    "\n",
    "data = '/data/dww78/mini_inat/'\n",
    "gpu = 1\n",
    "torch.cuda.set_device(gpu)\n",
    "workers = 8\n",
    "epoch = 10\n",
    "start_epoch = 0\n",
    "vbity = 20\n",
    "esize = 4\n",
    "\n",
    "way = 25\n",
    "evalway = 5\n",
    "bshot = 10\n",
    "trainshot = 20\n",
    "testshot = 10\n",
    "foldshot = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "908 227\n"
     ]
    }
   ],
   "source": [
    "# Load Training/Testing Data\n",
    "threshold = .15\n",
    "d_train = torch.load(data+'train_boxes.pth')\n",
    "d_test = torch.load(data+'val_boxes.pth')\n",
    "d_boxes = torch.load(data+'box_coords.pth')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4905, 0.4961, 0.4330],std=[0.1737, 0.1713, 0.1779])\n",
    "    ])\n",
    "\n",
    "def load_transform(path, pathdict, boxdict, transform, size, msize, flipping, masking):\n",
    "    flip = np.random.choice([True, False])\n",
    "    with open(path, 'rb') as f:\n",
    "        p = Image.open(f)\n",
    "        p = p.convert('RGB')\n",
    "    w,h = p.size\n",
    "    p = p.resize((size, size), Image.BILINEAR)\n",
    "    if flip and flipping:\n",
    "        p = p.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    t = transform(p)\n",
    "    if masking:\n",
    "        mask = np.zeros((h,w))\n",
    "        boxes = pathdict[path]\n",
    "        for b in boxes:\n",
    "            box = boxdict[b]\n",
    "            xmin = box[0]\n",
    "            xmax = box[2]+xmin\n",
    "            ymin = box[1]\n",
    "            ymax = box[3]+ymin\n",
    "            if not flip or not flipping:\n",
    "                mask[ymin:ymax, xmin:xmax] = 1\n",
    "            else:\n",
    "                mask[ymin:ymax, w-xmax:w-xmin] = 1\n",
    "        mask = resize(mask, (msize,msize), mode='constant', cval=0, anti_aliasing=False)\n",
    "        t = [t, (torch.FloatTensor(mask-threshold).sign()/2+.5).unsqueeze(0)]\n",
    "    return t\n",
    "\n",
    "class FoldSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, data_source, way):\n",
    "        iddict = dict()\n",
    "        for i,(_,cat) in enumerate(data_source.imgs):\n",
    "            if cat in iddict:\n",
    "                iddict[cat].append(i)\n",
    "            else:\n",
    "                iddict[cat] = [i]\n",
    "        self.iddict = iddict\n",
    "        self.way = way\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Build new dictionary, shuffle entries\n",
    "        trackdict = deepcopy(self.iddict)\n",
    "        for key in trackdict:\n",
    "            np.random.shuffle(trackdict[key])\n",
    "        # Choose categories, sample, eliminate small categories\n",
    "        idlist = []\n",
    "        while len(trackdict.keys()) >= self.way:\n",
    "            pcount = np.array([len(trackdict[k]) for k in list(trackdict.keys())])\n",
    "            cats = np.random.choice(list(trackdict.keys()), size=self.way, replace=False, p=pcount/sum(pcount))\n",
    "            for cat in cats:\n",
    "                for _ in range(foldshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "                if len(trackdict[cat]) < foldshot:\n",
    "                    trackdict.pop(cat)\n",
    "            # TODO: shuffle idlist batches\n",
    "            yield idlist\n",
    "            idlist = []\n",
    "\n",
    "class ProtoSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, data_source, way):\n",
    "        iddict = dict()\n",
    "        for i,(_,cat) in enumerate(data_source.imgs):\n",
    "            if cat in iddict:\n",
    "                iddict[cat].append(i)\n",
    "            else:\n",
    "                iddict[cat] = [i]\n",
    "        self.iddict = iddict\n",
    "        self.way = way\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Build new dictionary, shuffle entries\n",
    "        trackdict = deepcopy(self.iddict)\n",
    "        for key in trackdict:\n",
    "            np.random.shuffle(trackdict[key])\n",
    "        # Choose categories, sample, eliminate small categories\n",
    "        idlist = []\n",
    "        while len(trackdict.keys()) >= self.way:\n",
    "            pcount = np.array([len(trackdict[k]) for k in list(trackdict.keys())])\n",
    "            cats = np.random.choice(list(trackdict.keys()), size=self.way, replace=False, p=pcount/sum(pcount))\n",
    "            for cat in cats:\n",
    "                for _ in range(bshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "            for cat in cats:\n",
    "                for _ in range(trainshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "            for cat in cats:\n",
    "                for _ in range(testshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "                if len(trackdict[cat]) < bshot+trainshot+testshot:\n",
    "                    trackdict.pop(cat)\n",
    "            # TODO: shuffle idlist batches\n",
    "            yield idlist\n",
    "            idlist = []\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    data+'train', \n",
    "    loader = lambda x: load_transform(x, d_train, d_boxes, transform, 84, 21, True, True))\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    data+'val',\n",
    "    loader = lambda x: load_transform(x, d_test, d_boxes, transform, 84, 21, False, True))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler = FoldSampler(train_dataset, way),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_sampler = ProtoSampler(test_dataset, evalway),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "print('Data loaded!')\n",
    "print(len(train_dataset.classes), len(test_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113664  parameters in each neural net.\n"
     ]
    }
   ],
   "source": [
    "# Make Models\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(insize, outsize, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outsize)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.layers(inp)\n",
    "\n",
    "class PROTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PROTO, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            Block(4,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.AvgPool2d(10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.process(inp).view(inp.size(0),-1)\n",
    "        \n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, support, query, way):\n",
    "        assert support.size(0)%way == 0,\"Error: classes are not the same size!\"\n",
    "        shot = support.size(0)//way\n",
    "        support = support.view(way,shot,-1)\n",
    "        centroids = torch.mean(support, 1).view(support.size(0),-1)\n",
    "        if self.training:\n",
    "            centroids = centroids.unsqueeze(0).unsqueeze(0) # w 1 1 d\n",
    "            support = support.unsqueeze(2) # w s 1 d\n",
    "            eye = torch.eye(way).unsqueeze(1).unsqueeze(-1).cuda()/shot # w 1 w 1\n",
    "            rescaler = (torch.eye(way)/(shot-1) + torch.ones(way,way)).unsqueeze(1).unsqueeze(-1).cuda()\n",
    "            realc = (centroids - support*eye)*rescaler # w s w d\n",
    "            distmat = torch.sum((realc-support)**2, -1).squeeze().view(-1,way).neg() # ws w\n",
    "        else:\n",
    "            distmat = torch.sum((centroids.unsqueeze(0)-query.unsqueeze(1))**2,2).squeeze().neg()\n",
    "        probs = self.sm(distmat)\n",
    "        return probs\n",
    "    \n",
    "class bPROTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bPROTO, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            Block(3,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Block(64,64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.process(inp)\n",
    "        \n",
    "class bPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bPredictor, self).__init__()\n",
    "        self.sm = nn.Softmax(dim=-1)\n",
    "        self.upper = nn.Upsample(size=(84,84), mode='bilinear')\n",
    "        \n",
    "    def forward(self, inp, masks, way, shot):\n",
    "        if self.training:\n",
    "            support = inp.unsqueeze(-1) # B 64 21 21 1\n",
    "            m = masks.unsqueeze(1) # B 1 21 21\n",
    "            c = torch.stack([1-m, m], dim=-1) # B 1 21 21 2     (Positive class corresponds to index/label 1)\n",
    "            c = (c*support).contiguous().view(way,shot,inp.size(1),-1,2).mean(3) # W S 64 2         (Each image's prototypes)\n",
    "            c = (c.sum(1).unsqueeze(1) - c)/(shot-1) # W S 64 2        (Rescaled folded prototypes)\n",
    "            c = c.unsqueeze(3).unsqueeze(3) # W S 64 1 1 2\n",
    "\n",
    "            query = inp.view(way, -1, inp.size(1), inp.size(2), inp.size(3), 1) # W S 64 21 21 1\n",
    "        else:\n",
    "            support = inp[:way*shot].unsqueeze(-1) # B 64 21 21 1\n",
    "            m = masks.unsqueeze(1) # B 1 21 21\n",
    "            c = torch.stack([1-m, m], dim=-1) # B 1 21 21 2     (Positive class corresponds to index/label 1)\n",
    "            c = (c*support).contiguous().view(way,shot,inp.size(1),-1,2).mean(3).mean(1) # W 64 2\n",
    "            c = c.unsqueeze(2).unsqueeze(2).unsqueeze(1) # W 1 64 1 1 2\n",
    "\n",
    "            query = inp[way*shot:].view(way, -1, inp.size(1), inp.size(2), inp.size(3), 1) # W S 64 21 21 1\n",
    "        \n",
    "        distmat = ((c-query)**2).sum(2).neg().view(-1, inp.size(2), inp.size(3), 2) # B 21 21 2\n",
    "        probs = self.sm(distmat)[:,:,:,1]\n",
    "        return self.upper(probs.unsqueeze(1))\n",
    "    \n",
    "smodel = [PROTO().cuda() for i in range(esize)]\n",
    "bmodel = bPROTO()\n",
    "bmodel.load_state_dict(torch.load('detectors/saved_models/box_predictors.pth')[0])\n",
    "bmodel.cuda()\n",
    "predictor = Predictor().cuda()\n",
    "bpredictor = bPredictor().cuda()\n",
    "soptimizer = [optim.Adam(m.parameters(), lr=.001) for m in smodel]\n",
    "sscheduler = [optim.lr_scheduler.LambdaLR(o, lambda x: 1/(2**x)) for o in soptimizer]\n",
    "criterion = nn.NLLLoss().cuda()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "nweights = sum([i.numel() for i in list(smodel[0].parameters())])\n",
    "print(nweights,\" parameters in each neural net.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Define the Procedures\n",
    "\n",
    "def train(train_loader, epoch, gpu, vbity):\n",
    "    for model in smodel:\n",
    "        model.train()\n",
    "    bmodel.train()\n",
    "    predictor.train()\n",
    "    bpredictor.train()\n",
    "    targ = Variable(torch.LongTensor([i//foldshot for i in range(foldshot*way)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = [0]*esize\n",
    "    for i, ((inp, m), _) in enumerate(train_loader):\n",
    "        inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "        m = Variable(m).cuda(device = gpu, async=True)\n",
    "        with torch.no_grad():\n",
    "            masks = bpredictor(bmodel(inp), m, way, foldshot).detach()\n",
    "        inp = torch.cat([inp, masks], dim=1)\n",
    "        \n",
    "        for j in range(esize):\n",
    "            smodel[j].zero_grad()\n",
    "            out = predictor(smodel[j](inp), None, way)\n",
    "            loss = criterion(out, targ)\n",
    "            loss.backward()\n",
    "            soptimizer[j].step()\n",
    "        \n",
    "            allloss[j] += loss.item()\n",
    "            \n",
    "        if i%vbity == 0:\n",
    "            print('%d of approx. 192270'%(i*way*(foldshot)))\n",
    "    return [L/i for L in allloss]\n",
    "\n",
    "def validate(val_loader, gpu, vbity, reps, verbose):\n",
    "    for model in smodel:\n",
    "        model.eval()\n",
    "    bmodel.eval()\n",
    "    predictor.eval()\n",
    "    bpredictor.eval()\n",
    "    targ = Variable(torch.LongTensor([i//testshot for i in range(testshot*evalway)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = [0]*esize\n",
    "    acctracker = [[] for _ in range(esize)]\n",
    "    for r in range(reps):\n",
    "        for i, ((inp, m), _) in enumerate(val_loader):\n",
    "            inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "            m = Variable(m[evalway*bshot:]).cuda(device = gpu, async=True)\n",
    "            with torch.no_grad():\n",
    "                masks = bpredictor(bmodel(inp), m, evalway, bshot).detach()\n",
    "            inp = torch.cat([inp[evalway*bshot:], masks], dim=1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for j in range(esize):\n",
    "                    out = predictor(smodel[j](inp[:evalway*trainshot]), smodel[j](inp[evalway*trainshot:]), evalway)\n",
    "                    loss = criterion(out, targ)\n",
    "                    allloss[j] += loss.item()\n",
    "                    _,bins = torch.max(out,1)\n",
    "                    acc = torch.sum(torch.eq(bins,targ)).item()/testshot/evalway\n",
    "                    acctracker[j].append(acc)\n",
    "            if i%vbity == 0 and verbose:\n",
    "                print('Round %d of %d, %d of approx. 51716'%(r+1, reps, i*evalway*(trainshot+testshot)))\n",
    "    return [L/i for L in allloss], [np.mean(a) for a in acctracker], [1.96*np.sqrt(np.var(a)/len(a)) for a in acctracker]\n",
    "\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models prepared!\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(smodel):\n",
    "    model.load_state_dict(torch.load('saved_models/bpred_retrained.torch')[i])\n",
    "    model.cuda()\n",
    "print(\"Models prepared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 of 4, 0 of approx. 51716\n",
      "Round 1 of 4, 3000 of approx. 51716\n",
      "Round 1 of 4, 6000 of approx. 51716\n",
      "Round 1 of 4, 9000 of approx. 51716\n",
      "Round 1 of 4, 12000 of approx. 51716\n",
      "Round 1 of 4, 15000 of approx. 51716\n",
      "Round 1 of 4, 18000 of approx. 51716\n",
      "Round 1 of 4, 21000 of approx. 51716\n",
      "Round 1 of 4, 24000 of approx. 51716\n",
      "Round 1 of 4, 27000 of approx. 51716\n",
      "Round 1 of 4, 30000 of approx. 51716\n",
      "Round 2 of 4, 0 of approx. 51716\n",
      "Round 2 of 4, 3000 of approx. 51716\n",
      "Round 2 of 4, 6000 of approx. 51716\n",
      "Round 2 of 4, 9000 of approx. 51716\n",
      "Round 2 of 4, 12000 of approx. 51716\n",
      "Round 2 of 4, 15000 of approx. 51716\n",
      "Round 2 of 4, 18000 of approx. 51716\n",
      "Round 2 of 4, 21000 of approx. 51716\n",
      "Round 2 of 4, 24000 of approx. 51716\n",
      "Round 2 of 4, 27000 of approx. 51716\n",
      "Round 2 of 4, 30000 of approx. 51716\n",
      "Round 3 of 4, 0 of approx. 51716\n",
      "Round 3 of 4, 3000 of approx. 51716\n",
      "Round 3 of 4, 6000 of approx. 51716\n",
      "Round 3 of 4, 9000 of approx. 51716\n",
      "Round 3 of 4, 12000 of approx. 51716\n",
      "Round 3 of 4, 15000 of approx. 51716\n",
      "Round 3 of 4, 18000 of approx. 51716\n",
      "Round 3 of 4, 21000 of approx. 51716\n",
      "Round 3 of 4, 24000 of approx. 51716\n",
      "Round 3 of 4, 27000 of approx. 51716\n",
      "Round 3 of 4, 30000 of approx. 51716\n",
      "Round 4 of 4, 0 of approx. 51716\n",
      "Round 4 of 4, 3000 of approx. 51716\n",
      "Round 4 of 4, 6000 of approx. 51716\n",
      "Round 4 of 4, 9000 of approx. 51716\n",
      "Round 4 of 4, 12000 of approx. 51716\n",
      "Round 4 of 4, 15000 of approx. 51716\n",
      "Round 4 of 4, 18000 of approx. 51716\n",
      "Round 4 of 4, 21000 of approx. 51716\n",
      "Round 4 of 4, 24000 of approx. 51716\n",
      "Round 4 of 4, 27000 of approx. 51716\n",
      "Round 4 of 4, 30000 of approx. 51716\n",
      "Model 0 final score: 59.28 +- 1.08\n",
      "Model 1 final score: 59.44 +- 1.07\n",
      "Model 2 final score: 58.59 +- 1.07\n",
      "Model 3 final score: 60.05 +- 1.07\n"
     ]
    }
   ],
   "source": [
    "_, score, conf = validate(test_loader, gpu, vbity, 4, True)\n",
    "for i in range(esize):\n",
    "    print('Model %d final score: %.2f +- %.2f'%(i, score[i]*100, conf[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                             RETRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained models\n",
    "\n",
    "ts,m,o = torch.load('saved_models/retraining_folded_initial.torch')\n",
    "for i in range(esize):\n",
    "    smodel[i].load_state_dict(m[i])\n",
    "    soptimizer[i].load_state_dict(o[i])\n",
    "trainlosses, testlosses, acctracker = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of approx. 192270\n",
      "3000 of approx. 192270\n",
      "6000 of approx. 192270\n",
      "9000 of approx. 192270\n",
      "12000 of approx. 192270\n",
      "15000 of approx. 192270\n",
      "18000 of approx. 192270\n",
      "21000 of approx. 192270\n",
      "24000 of approx. 192270\n",
      "27000 of approx. 192270\n",
      "30000 of approx. 192270\n",
      "33000 of approx. 192270\n",
      "36000 of approx. 192270\n",
      "39000 of approx. 192270\n",
      "42000 of approx. 192270\n",
      "45000 of approx. 192270\n",
      "48000 of approx. 192270\n",
      "51000 of approx. 192270\n",
      "54000 of approx. 192270\n",
      "57000 of approx. 192270\n",
      "60000 of approx. 192270\n",
      "63000 of approx. 192270\n",
      "66000 of approx. 192270\n",
      "69000 of approx. 192270\n",
      "72000 of approx. 192270\n",
      "75000 of approx. 192270\n",
      "78000 of approx. 192270\n",
      "81000 of approx. 192270\n",
      "84000 of approx. 192270\n",
      "87000 of approx. 192270\n",
      "90000 of approx. 192270\n",
      "93000 of approx. 192270\n"
     ]
    }
   ],
   "source": [
    "# Do the Thing!\n",
    "\n",
    "start = time.time()\n",
    "# trainlosses, testlosses, acctracker = [[] for _ in range(esize)],[[] for _ in range(esize)],[[] for _ in range(esize)]\n",
    "epochs = 5*epoch\n",
    "for e in range(epochs):\n",
    "    # Adjust learnrate\n",
    "    if e%epoch == 0:\n",
    "        [s.step() for s in sscheduler]\n",
    "    \n",
    "    # Train for one epoch\n",
    "    trainloss = train(train_loader, e, gpu, vbity)\n",
    "    \n",
    "    # Evaluate, single pass\n",
    "    testloss, acc, _ = validate(test_loader, gpu, vbity, 1, True)\n",
    "    \n",
    "    # update the precision graph, report\n",
    "    display.clear_output(wait=True)\n",
    "    for j in range(esize):\n",
    "        trainlosses[j].append(trainloss[j])\n",
    "        testlosses[j].append(testloss[j])\n",
    "        acctracker[j].append(acc[j])\n",
    "    pl.figure(1, figsize=(15,15))\n",
    "    for i in range(esize):\n",
    "        pl.subplot(esize,2,2*i+1)\n",
    "        pl.plot(trainlosses[i])\n",
    "        pl.plot(testlosses[i])\n",
    "        pl.axvline(x=49)\n",
    "        pl.ylim((0,3))\n",
    "        pl.title(\"Loss: Training Blue, Validation Gold\")\n",
    "        pl.subplot(esize,2,2*i+2)\n",
    "        pl.plot(acctracker[i][::-1])\n",
    "        pl.axvline(x=len(trainlosses[i])-50)\n",
    "        pl.ylim((0.4,.9))\n",
    "        pl.title(\"Validation Acc\")\n",
    "    pl.show()\n",
    "    print(\"Train loss is: \"+str(trainloss)+\n",
    "            \"\\nValidation accuracy is: \"+str(acc)+\n",
    "            \"\\nValidation loss is: \"+str(testloss)+\"\\n\")\n",
    "    \n",
    "    print(\"%.2f hours to completion\"%(  (time.time()-start)/(e+1)*(epochs-e)/3600  ))\n",
    "    print()\n",
    "print((time.time()-start)/3600, \"hours total\") \n",
    "_, score, conf = validate(test_loader, gpu, vbity, 10, False)\n",
    "for i in range(esize):\n",
    "    print('Model %d final score: %.2f +- %.2f'%(i, score[i]*100, conf[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix this code, save models\n",
    "\n",
    "torch.save(tuple([m.cpu().state_dict() for m in smodel]), 'saved_models/bpred_retrained.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
