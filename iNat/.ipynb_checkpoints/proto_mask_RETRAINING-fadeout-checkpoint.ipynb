{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "from IPython import display\n",
    "from copy import deepcopy\n",
    "from skimage.transform import resize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Important Values\n",
    "\n",
    "data = '/data/mini_inat/'\n",
    "gpu = 2\n",
    "torch.cuda.set_device(gpu)\n",
    "workers = 8\n",
    "epoch = 10\n",
    "start_epoch = 0\n",
    "vbity = 20\n",
    "\n",
    "way = 20\n",
    "evalway = 5\n",
    "trainshot = 5\n",
    "testshot = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113664  parameters in neural net.\n"
     ]
    }
   ],
   "source": [
    "# Make Model\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(insize, outsize, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outsize)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.layers(inp)\n",
    "\n",
    "class PROTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PROTO, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            Block(4,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.AvgPool2d(10)\n",
    "        )\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, inp, way, supshot):\n",
    "        out = self.process(inp[:,:,:,:]).view(inp.size(0),-1)\n",
    "        support = out[:way*supshot].view(way,supshot,-1)\n",
    "        support = torch.mean(support, 1).view(support.size(0),-1)\n",
    "        query = out[way*supshot:]\n",
    "        distmat = torch.sum((support.unsqueeze(0)-query.unsqueeze(1))**2,2).squeeze().neg()\n",
    "        probs = self.sm(distmat)\n",
    "        return probs\n",
    "\n",
    "model = PROTO().cuda(device = gpu)\n",
    "optimizer = optim.Adam(model.parameters(), lr=.001/8)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda x: 1/(2**x))\n",
    "criterion = nn.NLLLoss().cuda(device = gpu)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "nweights = sum([i.numel() for i in list(model.parameters())])\n",
    "print(nweights,\" parameters in neural net.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('saved_models/fourthchannelmodel_cpu.torch')\n",
    "model.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load Training/Testing Data\n",
    "\n",
    "d_train = torch.load(data+'train_boxes.pth')\n",
    "d_test = torch.load(data+'val_boxes.pth')\n",
    "d_boxes = torch.load(data+'box_coords.pth')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4905, 0.4961, 0.4330],std=[0.1737, 0.1713, 0.1779])\n",
    "    ])\n",
    "\n",
    "def load_transform(path, pathdict, boxdict, transform, size, flipping, masking):\n",
    "    flip = np.random.choice([True, False])\n",
    "    with open(path, 'rb') as f:\n",
    "        p = Image.open(f)\n",
    "        p = p.convert('RGB')\n",
    "    w,h = p.size\n",
    "    p = p.resize((size, size), Image.BILINEAR)\n",
    "    if flip and flipping:\n",
    "        p = p.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    t = transform(p)\n",
    "    if masking:\n",
    "        mask = np.zeros((h,w))\n",
    "        boxes = pathdict[path]\n",
    "        for b in boxes:\n",
    "            box = boxdict[b]\n",
    "            xmin = box[0]\n",
    "            xmax = box[2]+xmin\n",
    "            ymin = box[1]\n",
    "            ymax = box[3]+ymin\n",
    "            if not flip or not flipping:\n",
    "                mask[ymin:ymax, xmin:xmax] = 1\n",
    "            else:\n",
    "                mask[ymin:ymax, w-xmax:w-xmin] = 1\n",
    "        mask = resize(mask, (size,size), mode='constant', cval=0)\n",
    "        t = torch.cat([t, torch.FloatTensor(mask).unsqueeze(0)], dim=0)\n",
    "    return t\n",
    "\n",
    "class ProtoSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, data_source, way):\n",
    "        iddict = dict()\n",
    "        for i,(_,cat) in enumerate(data_source.imgs):\n",
    "            if cat in iddict:\n",
    "                iddict[cat].append(i)\n",
    "            else:\n",
    "                iddict[cat] = [i]\n",
    "        self.iddict = iddict\n",
    "        self.way = way\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Build new dictionary, shuffle entries\n",
    "        trackdict = deepcopy(self.iddict)\n",
    "        for key in trackdict:\n",
    "            np.random.shuffle(trackdict[key])\n",
    "        # Choose categories, sample, eliminate small categories\n",
    "        idlist = []\n",
    "        while len(trackdict.keys()) >= self.way:\n",
    "            cats = np.random.choice(list(trackdict.keys()), size=self.way, replace=False)\n",
    "            for cat in cats:\n",
    "                for _ in range(trainshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "            for cat in cats:\n",
    "                for _ in range(testshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "                if len(trackdict[cat]) < trainshot+testshot:\n",
    "                    trackdict.pop(cat)\n",
    "            yield idlist\n",
    "            idlist = []\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    data+'train', \n",
    "    loader = lambda x: load_transform(x, d_train, d_boxes, transform, 84, True, True))\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    data+'val',\n",
    "    loader = lambda x: load_transform(x, d_test, d_boxes, transform, 84, False, True))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler = ProtoSampler(train_dataset, way),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_sampler = ProtoSampler(test_dataset, evalway),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Define the Procedures\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, gpu, vbity):\n",
    "    model.train()\n",
    "    targ = Variable(torch.LongTensor([i//testshot for i in range(testshot*way)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = 0\n",
    "    for i, (inp, _) in enumerate(train_loader):\n",
    "        inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "        \n",
    "        # Zero out the masks\n",
    "        inp[way*trainshot:,-1,:,:] = 0\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out = model(inp, way, trainshot)\n",
    "        loss = criterion(out, targ)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        allloss += loss.item()\n",
    "        if i%vbity == 0:\n",
    "            print('%d of approx. 192270'%(i*way*(trainshot+testshot)))\n",
    "    return allloss/i\n",
    "\n",
    "def validate(val_loader, model, criterion, gpu, vbity, reps, verbose):\n",
    "    model.eval()\n",
    "    targ = Variable(torch.LongTensor([i//testshot for i in range(testshot*evalway)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = 0\n",
    "    acctracker = []\n",
    "    for r in range(reps):\n",
    "        for i, (inp, _) in enumerate(val_loader):\n",
    "            inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "            \n",
    "            # Zero out the masks\n",
    "            inp[evalway*trainshot:,-1,:,:] = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(inp, evalway, trainshot)\n",
    "                loss = criterion(out, targ)\n",
    "                allloss += loss.item()\n",
    "                _,bins = torch.max(out,1)\n",
    "                acc = torch.sum(torch.eq(bins,targ)).item()/testshot/evalway\n",
    "                acctracker.append(acc)\n",
    "            if i%vbity == 0 and verbose:\n",
    "                print('Round %d of %d, %d of approx. 51716'%(r+1, reps, i*evalway*(trainshot+testshot)))\n",
    "    return allloss/i, np.mean(acctracker), 1.96*np.sqrt(np.var(acctracker)/len(acctracker))\n",
    "\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 of 10, 0 of approx. 51716\n",
      "Round 1 of 10, 2000 of approx. 51716\n",
      "Round 1 of 10, 4000 of approx. 51716\n",
      "Round 1 of 10, 6000 of approx. 51716\n",
      "Round 1 of 10, 8000 of approx. 51716\n",
      "Round 1 of 10, 10000 of approx. 51716\n",
      "Round 1 of 10, 12000 of approx. 51716\n",
      "Round 1 of 10, 14000 of approx. 51716\n",
      "Round 1 of 10, 16000 of approx. 51716\n",
      "Round 1 of 10, 18000 of approx. 51716\n",
      "Round 1 of 10, 20000 of approx. 51716\n",
      "Round 1 of 10, 22000 of approx. 51716\n",
      "Round 1 of 10, 24000 of approx. 51716\n",
      "Round 1 of 10, 26000 of approx. 51716\n",
      "Round 1 of 10, 28000 of approx. 51716\n",
      "Round 1 of 10, 30000 of approx. 51716\n",
      "Round 1 of 10, 32000 of approx. 51716\n",
      "Round 1 of 10, 34000 of approx. 51716\n",
      "Round 1 of 10, 36000 of approx. 51716\n",
      "Round 1 of 10, 38000 of approx. 51716\n",
      "Round 1 of 10, 40000 of approx. 51716\n",
      "Round 1 of 10, 42000 of approx. 51716\n",
      "Round 1 of 10, 44000 of approx. 51716\n",
      "Round 1 of 10, 46000 of approx. 51716\n",
      "Round 1 of 10, 48000 of approx. 51716\n",
      "Round 2 of 10, 0 of approx. 51716\n",
      "Round 2 of 10, 2000 of approx. 51716\n",
      "Round 2 of 10, 4000 of approx. 51716\n",
      "Round 2 of 10, 6000 of approx. 51716\n",
      "Round 2 of 10, 8000 of approx. 51716\n",
      "Round 2 of 10, 10000 of approx. 51716\n",
      "Round 2 of 10, 12000 of approx. 51716\n",
      "Round 2 of 10, 14000 of approx. 51716\n",
      "Round 2 of 10, 16000 of approx. 51716\n",
      "Round 2 of 10, 18000 of approx. 51716\n",
      "Round 2 of 10, 20000 of approx. 51716\n",
      "Round 2 of 10, 22000 of approx. 51716\n",
      "Round 2 of 10, 24000 of approx. 51716\n",
      "Round 2 of 10, 26000 of approx. 51716\n",
      "Round 2 of 10, 28000 of approx. 51716\n",
      "Round 2 of 10, 30000 of approx. 51716\n",
      "Round 2 of 10, 32000 of approx. 51716\n",
      "Round 2 of 10, 34000 of approx. 51716\n",
      "Round 2 of 10, 36000 of approx. 51716\n",
      "Round 2 of 10, 38000 of approx. 51716\n",
      "Round 2 of 10, 40000 of approx. 51716\n",
      "Round 2 of 10, 42000 of approx. 51716\n",
      "Round 2 of 10, 44000 of approx. 51716\n",
      "Round 2 of 10, 46000 of approx. 51716\n",
      "Round 2 of 10, 48000 of approx. 51716\n",
      "Round 3 of 10, 0 of approx. 51716\n",
      "Round 3 of 10, 2000 of approx. 51716\n",
      "Round 3 of 10, 4000 of approx. 51716\n",
      "Round 3 of 10, 6000 of approx. 51716\n",
      "Round 3 of 10, 8000 of approx. 51716\n",
      "Round 3 of 10, 10000 of approx. 51716\n",
      "Round 3 of 10, 12000 of approx. 51716\n",
      "Round 3 of 10, 14000 of approx. 51716\n",
      "Round 3 of 10, 16000 of approx. 51716\n",
      "Round 3 of 10, 18000 of approx. 51716\n",
      "Round 3 of 10, 20000 of approx. 51716\n",
      "Round 3 of 10, 22000 of approx. 51716\n",
      "Round 3 of 10, 24000 of approx. 51716\n",
      "Round 3 of 10, 26000 of approx. 51716\n",
      "Round 3 of 10, 28000 of approx. 51716\n",
      "Round 3 of 10, 30000 of approx. 51716\n",
      "Round 3 of 10, 32000 of approx. 51716\n",
      "Round 3 of 10, 34000 of approx. 51716\n",
      "Round 3 of 10, 36000 of approx. 51716\n",
      "Round 3 of 10, 38000 of approx. 51716\n",
      "Round 3 of 10, 40000 of approx. 51716\n",
      "Round 3 of 10, 42000 of approx. 51716\n",
      "Round 3 of 10, 44000 of approx. 51716\n",
      "Round 3 of 10, 46000 of approx. 51716\n",
      "Round 3 of 10, 48000 of approx. 51716\n",
      "Round 4 of 10, 0 of approx. 51716\n",
      "Round 4 of 10, 2000 of approx. 51716\n",
      "Round 4 of 10, 4000 of approx. 51716\n",
      "Round 4 of 10, 6000 of approx. 51716\n",
      "Round 4 of 10, 8000 of approx. 51716\n",
      "Round 4 of 10, 10000 of approx. 51716\n",
      "Round 4 of 10, 12000 of approx. 51716\n",
      "Round 4 of 10, 14000 of approx. 51716\n",
      "Round 4 of 10, 16000 of approx. 51716\n",
      "Round 4 of 10, 18000 of approx. 51716\n",
      "Round 4 of 10, 20000 of approx. 51716\n",
      "Round 4 of 10, 22000 of approx. 51716\n",
      "Round 4 of 10, 24000 of approx. 51716\n",
      "Round 4 of 10, 26000 of approx. 51716\n",
      "Round 4 of 10, 28000 of approx. 51716\n",
      "Round 4 of 10, 30000 of approx. 51716\n",
      "Round 4 of 10, 32000 of approx. 51716\n",
      "Round 4 of 10, 34000 of approx. 51716\n",
      "Round 4 of 10, 36000 of approx. 51716\n",
      "Round 4 of 10, 38000 of approx. 51716\n",
      "Round 4 of 10, 40000 of approx. 51716\n",
      "Round 4 of 10, 42000 of approx. 51716\n",
      "Round 4 of 10, 44000 of approx. 51716\n",
      "Round 4 of 10, 46000 of approx. 51716\n",
      "Round 4 of 10, 48000 of approx. 51716\n",
      "Round 5 of 10, 0 of approx. 51716\n",
      "Round 5 of 10, 2000 of approx. 51716\n",
      "Round 5 of 10, 4000 of approx. 51716\n",
      "Round 5 of 10, 6000 of approx. 51716\n",
      "Round 5 of 10, 8000 of approx. 51716\n",
      "Round 5 of 10, 10000 of approx. 51716\n",
      "Round 5 of 10, 12000 of approx. 51716\n",
      "Round 5 of 10, 14000 of approx. 51716\n",
      "Round 5 of 10, 16000 of approx. 51716\n",
      "Round 5 of 10, 18000 of approx. 51716\n",
      "Round 5 of 10, 20000 of approx. 51716\n",
      "Round 5 of 10, 22000 of approx. 51716\n",
      "Round 5 of 10, 24000 of approx. 51716\n",
      "Round 5 of 10, 26000 of approx. 51716\n",
      "Round 5 of 10, 28000 of approx. 51716\n",
      "Round 5 of 10, 30000 of approx. 51716\n",
      "Round 5 of 10, 32000 of approx. 51716\n",
      "Round 5 of 10, 34000 of approx. 51716\n",
      "Round 5 of 10, 36000 of approx. 51716\n",
      "Round 5 of 10, 38000 of approx. 51716\n",
      "Round 5 of 10, 40000 of approx. 51716\n",
      "Round 5 of 10, 42000 of approx. 51716\n",
      "Round 5 of 10, 44000 of approx. 51716\n",
      "Round 5 of 10, 46000 of approx. 51716\n",
      "Round 5 of 10, 48000 of approx. 51716\n",
      "Round 6 of 10, 0 of approx. 51716\n",
      "Round 6 of 10, 2000 of approx. 51716\n",
      "Round 6 of 10, 4000 of approx. 51716\n",
      "Round 6 of 10, 6000 of approx. 51716\n",
      "Round 6 of 10, 8000 of approx. 51716\n",
      "Round 6 of 10, 10000 of approx. 51716\n",
      "Round 6 of 10, 12000 of approx. 51716\n",
      "Round 6 of 10, 14000 of approx. 51716\n",
      "Round 6 of 10, 16000 of approx. 51716\n",
      "Round 6 of 10, 18000 of approx. 51716\n",
      "Round 6 of 10, 20000 of approx. 51716\n",
      "Round 6 of 10, 22000 of approx. 51716\n",
      "Round 6 of 10, 24000 of approx. 51716\n",
      "Round 6 of 10, 26000 of approx. 51716\n",
      "Round 6 of 10, 28000 of approx. 51716\n",
      "Round 6 of 10, 30000 of approx. 51716\n",
      "Round 6 of 10, 32000 of approx. 51716\n",
      "Round 6 of 10, 34000 of approx. 51716\n",
      "Round 6 of 10, 36000 of approx. 51716\n",
      "Round 6 of 10, 38000 of approx. 51716\n",
      "Round 6 of 10, 40000 of approx. 51716\n",
      "Round 6 of 10, 42000 of approx. 51716\n",
      "Round 6 of 10, 44000 of approx. 51716\n",
      "Round 6 of 10, 46000 of approx. 51716\n",
      "Round 6 of 10, 48000 of approx. 51716\n",
      "Round 7 of 10, 0 of approx. 51716\n",
      "Round 7 of 10, 2000 of approx. 51716\n",
      "Round 7 of 10, 4000 of approx. 51716\n",
      "Round 7 of 10, 6000 of approx. 51716\n",
      "Round 7 of 10, 8000 of approx. 51716\n",
      "Round 7 of 10, 10000 of approx. 51716\n",
      "Round 7 of 10, 12000 of approx. 51716\n",
      "Round 7 of 10, 14000 of approx. 51716\n",
      "Round 7 of 10, 16000 of approx. 51716\n",
      "Round 7 of 10, 18000 of approx. 51716\n",
      "Round 7 of 10, 20000 of approx. 51716\n",
      "Round 7 of 10, 22000 of approx. 51716\n",
      "Round 7 of 10, 24000 of approx. 51716\n",
      "Round 7 of 10, 26000 of approx. 51716\n",
      "Round 7 of 10, 28000 of approx. 51716\n",
      "Round 7 of 10, 30000 of approx. 51716\n",
      "Round 7 of 10, 32000 of approx. 51716\n",
      "Round 7 of 10, 34000 of approx. 51716\n",
      "Round 7 of 10, 36000 of approx. 51716\n",
      "Round 7 of 10, 38000 of approx. 51716\n",
      "Round 7 of 10, 40000 of approx. 51716\n",
      "Round 7 of 10, 42000 of approx. 51716\n",
      "Round 7 of 10, 44000 of approx. 51716\n",
      "Round 7 of 10, 46000 of approx. 51716\n",
      "Round 7 of 10, 48000 of approx. 51716\n",
      "Round 8 of 10, 0 of approx. 51716\n",
      "Round 8 of 10, 2000 of approx. 51716\n",
      "Round 8 of 10, 4000 of approx. 51716\n",
      "Round 8 of 10, 6000 of approx. 51716\n",
      "Round 8 of 10, 8000 of approx. 51716\n",
      "Round 8 of 10, 10000 of approx. 51716\n",
      "Round 8 of 10, 12000 of approx. 51716\n",
      "Round 8 of 10, 14000 of approx. 51716\n",
      "Round 8 of 10, 16000 of approx. 51716\n",
      "Round 8 of 10, 18000 of approx. 51716\n",
      "Round 8 of 10, 20000 of approx. 51716\n",
      "Round 8 of 10, 22000 of approx. 51716\n",
      "Round 8 of 10, 24000 of approx. 51716\n",
      "Round 8 of 10, 26000 of approx. 51716\n",
      "Round 8 of 10, 28000 of approx. 51716\n",
      "Round 8 of 10, 30000 of approx. 51716\n",
      "Round 8 of 10, 32000 of approx. 51716\n",
      "Round 8 of 10, 34000 of approx. 51716\n",
      "Round 8 of 10, 36000 of approx. 51716\n",
      "Round 8 of 10, 38000 of approx. 51716\n",
      "Round 8 of 10, 40000 of approx. 51716\n",
      "Round 8 of 10, 42000 of approx. 51716\n",
      "Round 8 of 10, 44000 of approx. 51716\n",
      "Round 8 of 10, 46000 of approx. 51716\n",
      "Round 8 of 10, 48000 of approx. 51716\n",
      "Round 9 of 10, 0 of approx. 51716\n",
      "Round 9 of 10, 2000 of approx. 51716\n",
      "Round 9 of 10, 4000 of approx. 51716\n",
      "Round 9 of 10, 6000 of approx. 51716\n",
      "Round 9 of 10, 8000 of approx. 51716\n",
      "Round 9 of 10, 10000 of approx. 51716\n",
      "Round 9 of 10, 12000 of approx. 51716\n",
      "Round 9 of 10, 14000 of approx. 51716\n",
      "Round 9 of 10, 16000 of approx. 51716\n",
      "Round 9 of 10, 18000 of approx. 51716\n",
      "Round 9 of 10, 20000 of approx. 51716\n",
      "Round 9 of 10, 22000 of approx. 51716\n",
      "Round 9 of 10, 24000 of approx. 51716\n",
      "Round 9 of 10, 26000 of approx. 51716\n",
      "Round 9 of 10, 28000 of approx. 51716\n",
      "Round 9 of 10, 30000 of approx. 51716\n",
      "Round 9 of 10, 32000 of approx. 51716\n",
      "Round 9 of 10, 34000 of approx. 51716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 9 of 10, 36000 of approx. 51716\n",
      "Round 9 of 10, 38000 of approx. 51716\n",
      "Round 9 of 10, 40000 of approx. 51716\n",
      "Round 9 of 10, 42000 of approx. 51716\n",
      "Round 9 of 10, 44000 of approx. 51716\n",
      "Round 9 of 10, 46000 of approx. 51716\n",
      "Round 9 of 10, 48000 of approx. 51716\n",
      "Round 10 of 10, 0 of approx. 51716\n",
      "Round 10 of 10, 2000 of approx. 51716\n",
      "Round 10 of 10, 4000 of approx. 51716\n",
      "Round 10 of 10, 6000 of approx. 51716\n",
      "Round 10 of 10, 8000 of approx. 51716\n",
      "Round 10 of 10, 10000 of approx. 51716\n",
      "Round 10 of 10, 12000 of approx. 51716\n",
      "Round 10 of 10, 14000 of approx. 51716\n",
      "Round 10 of 10, 16000 of approx. 51716\n",
      "Round 10 of 10, 18000 of approx. 51716\n",
      "Round 10 of 10, 20000 of approx. 51716\n",
      "Round 10 of 10, 22000 of approx. 51716\n",
      "Round 10 of 10, 24000 of approx. 51716\n",
      "Round 10 of 10, 26000 of approx. 51716\n",
      "Round 10 of 10, 28000 of approx. 51716\n",
      "Round 10 of 10, 30000 of approx. 51716\n",
      "Round 10 of 10, 32000 of approx. 51716\n",
      "Round 10 of 10, 34000 of approx. 51716\n",
      "Round 10 of 10, 36000 of approx. 51716\n",
      "Round 10 of 10, 38000 of approx. 51716\n",
      "Round 10 of 10, 40000 of approx. 51716\n",
      "Round 10 of 10, 42000 of approx. 51716\n",
      "Round 10 of 10, 44000 of approx. 51716\n",
      "Round 10 of 10, 46000 of approx. 51716\n",
      "Round 10 of 10, 48000 of approx. 51716\n",
      "Final score: 47.55 +- 0.27\n"
     ]
    }
   ],
   "source": [
    "_, score, conf = validate(test_loader, model, criterion, gpu, vbity, 10, True)\n",
    "print('Final score: %.2f +- %.2f'%(score*100, conf*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of approx. 192270\n",
      "8000 of approx. 192270\n",
      "16000 of approx. 192270\n",
      "24000 of approx. 192270\n",
      "32000 of approx. 192270\n",
      "40000 of approx. 192270\n"
     ]
    }
   ],
   "source": [
    "# Do the Thing!\n",
    "\n",
    "start = time.time()\n",
    "trainlosses, testlosses, acctracker, spreadtracker = [], [], [], []\n",
    "epochs = 5*epoch\n",
    "for e in range(epochs):\n",
    "    # Adjust learnrate\n",
    "    if e%epoch == 0 and e>0:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Train for one epoch\n",
    "    trainloss = train(train_loader, model, criterion, optimizer, e, gpu, vbity)\n",
    "    \n",
    "    # Evaluate, single pass\n",
    "    testloss, acc, spread = validate(test_loader, model, criterion, gpu, vbity, 1, True)\n",
    "    \n",
    "    # update the precision graph, report\n",
    "    display.clear_output(wait=True)\n",
    "    trainlosses.append(trainloss)\n",
    "    testlosses.append(testloss)\n",
    "    acctracker.append(acc)\n",
    "    spreadtracker.append(spread)\n",
    "    pl.figure(1, figsize=(15,5))\n",
    "    pl.subplot(1,2,1)\n",
    "    pl.plot(trainlosses)\n",
    "    pl.plot(testlosses)\n",
    "    pl.ylim((.5,3))\n",
    "    pl.title(\"Loss: Training Blue, Validation Gold\")\n",
    "    pl.subplot(1,2,2)\n",
    "    pl.plot(acctracker[::-1])\n",
    "    pl.plot(np.array(acctracker[::-1])-np.array(spreadtracker[::-1]), alpha=.5, c='blue')\n",
    "    pl.plot(np.array(acctracker[::-1])+np.array(spreadtracker[::-1]), alpha=.5, c='blue')\n",
    "    pl.ylim((0.3,.8))\n",
    "    pl.title(\"Validation Acc\")\n",
    "    pl.show()\n",
    "    print(\"Train loss is: \"+str(trainloss)+\n",
    "            \"\\nValidation accuracy is: \"+str(acc)+\n",
    "            \"\\nValidation loss is: \"+str(testloss)+\"\\n\")\n",
    "    \n",
    "    print(\"%.2f hours to completion\"%(  (time.time()-start)/(e+1)*(epochs-e)/3600  ))\n",
    "    print()\n",
    "print((time.time()-start)/3600) \n",
    "_, score, conf = validate(test_loader, model, criterion, gpu, vbity, 10, False)\n",
    "print('Final score: %.2f +- %.2f'%(score*100, conf*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-682a2aafde74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'baselinemodel.torch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'baselinemodel.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed,model,losstracker,evallosstracker,evalacctracker = torch.load('saved_models/naive_4.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
