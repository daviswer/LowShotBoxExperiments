{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "from IPython import display\n",
    "from copy import deepcopy\n",
    "from skimage.transform import resize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Important Values\n",
    "\n",
    "data = '/data/dww78/mini_inat/'\n",
    "gpu = 1\n",
    "torch.cuda.set_device(gpu)\n",
    "workers = 8\n",
    "epoch = 10\n",
    "start_epoch = 0\n",
    "vbity = 20\n",
    "esize = 4\n",
    "\n",
    "way = 30\n",
    "evalway = 5\n",
    "trainshot = 5\n",
    "testshot = 10\n",
    "foldshot = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "908 227\n"
     ]
    }
   ],
   "source": [
    "# Load Training/Testing Data\n",
    "threshold = .15\n",
    "d_train = torch.load(data+'train_boxes.pth')\n",
    "d_test = torch.load(data+'val_boxes.pth')\n",
    "d_boxes = torch.load(data+'box_coords.pth')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4905, 0.4961, 0.4330],std=[0.1737, 0.1713, 0.1779])\n",
    "    ])\n",
    "\n",
    "def load_transform(path, pathdict, boxdict, transform, size, msize, flipping, masking):\n",
    "    flip = np.random.choice([True, False])\n",
    "    with open(path, 'rb') as f:\n",
    "        p = Image.open(f)\n",
    "        p = p.convert('RGB')\n",
    "    w,h = p.size\n",
    "    p = p.resize((size, size), Image.BILINEAR)\n",
    "    if flip and flipping:\n",
    "        p = p.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    t = transform(p)\n",
    "    if masking:\n",
    "        mask = np.zeros((h,w))\n",
    "        boxes = pathdict[path]\n",
    "        for b in boxes:\n",
    "            box = boxdict[b]\n",
    "            xmin = box[0]\n",
    "            xmax = box[2]+xmin\n",
    "            ymin = box[1]\n",
    "            ymax = box[3]+ymin\n",
    "            if not flip or not flipping:\n",
    "                mask[ymin:ymax, xmin:xmax] = 1\n",
    "            else:\n",
    "                mask[ymin:ymax, w-xmax:w-xmin] = 1\n",
    "        mask = resize(mask, (msize,msize), mode='constant', cval=0, anti_aliasing=False)\n",
    "        t = [t, (torch.FloatTensor(mask-threshold).sign()/2+.5).unsqueeze(0)]\n",
    "    return t\n",
    "\n",
    "class FoldSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, data_source, way):\n",
    "        iddict = dict()\n",
    "        for i,(_,cat) in enumerate(data_source.imgs):\n",
    "            if cat in iddict:\n",
    "                iddict[cat].append(i)\n",
    "            else:\n",
    "                iddict[cat] = [i]\n",
    "        self.iddict = iddict\n",
    "        self.way = way\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Build new dictionary, shuffle entries\n",
    "        trackdict = deepcopy(self.iddict)\n",
    "        for key in trackdict:\n",
    "            np.random.shuffle(trackdict[key])\n",
    "        # Choose categories, sample, eliminate small categories\n",
    "        idlist = []\n",
    "        while len(trackdict.keys()) >= self.way:\n",
    "            pcount = np.array([len(trackdict[k]) for k in list(trackdict.keys())])\n",
    "            cats = np.random.choice(list(trackdict.keys()), size=self.way, replace=False, p=pcount/sum(pcount))\n",
    "            for cat in cats:\n",
    "                for _ in range(foldshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "                if len(trackdict[cat]) < foldshot:\n",
    "                    trackdict.pop(cat)\n",
    "            # TODO: shuffle idlist batches\n",
    "            yield idlist\n",
    "            idlist = []\n",
    "\n",
    "class ProtoSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, data_source, way):\n",
    "        iddict = dict()\n",
    "        for i,(_,cat) in enumerate(data_source.imgs):\n",
    "            if cat in iddict:\n",
    "                iddict[cat].append(i)\n",
    "            else:\n",
    "                iddict[cat] = [i]\n",
    "        self.iddict = iddict\n",
    "        self.way = way\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Build new dictionary, shuffle entries\n",
    "        trackdict = deepcopy(self.iddict)\n",
    "        for key in trackdict:\n",
    "            np.random.shuffle(trackdict[key])\n",
    "        # Choose categories, sample, eliminate small categories\n",
    "        idlist = []\n",
    "        while len(trackdict.keys()) >= self.way:\n",
    "            pcount = np.array([len(trackdict[k]) for k in list(trackdict.keys())])\n",
    "            cats = np.random.choice(list(trackdict.keys()), size=self.way, replace=False, p=pcount/sum(pcount))\n",
    "            for cat in cats:\n",
    "                for _ in range(trainshot*2):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "            for cat in cats:\n",
    "                for _ in range(testshot):\n",
    "                    idlist.append(trackdict[cat].pop())\n",
    "                if len(trackdict[cat]) < trainshot*2+testshot:\n",
    "                    trackdict.pop(cat)\n",
    "            # TODO: shuffle idlist batches\n",
    "            yield idlist\n",
    "            idlist = []\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    data+'train', \n",
    "    loader = lambda x: load_transform(x, d_train, d_boxes, transform, 84, 21, True, True))\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    data+'val',\n",
    "    loader = lambda x: load_transform(x, d_test, d_boxes, transform, 84, 21, False, True))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler = FoldSampler(train_dataset, way),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_sampler = ProtoSampler(test_dataset, evalway),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "print('Data loaded!')\n",
    "print(len(train_dataset.classes), len(test_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113664  parameters in each neural net.\n"
     ]
    }
   ],
   "source": [
    "# Make Models\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(insize, outsize, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(outsize)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.layers(inp)\n",
    "\n",
    "class PROTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PROTO, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            Block(4,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.AvgPool2d(10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.process(inp).view(inp.size(0),-1)\n",
    "        \n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, support, query, way):\n",
    "        assert support.size(0)%way == 0,\"Error: classes are not the same size!\"\n",
    "        shot = support.size(0)//way\n",
    "        support = support.view(way,shot,-1)\n",
    "        centroids = torch.mean(support, 1).view(support.size(0),-1)\n",
    "        if self.training:\n",
    "            centroids = centroids.unsqueeze(0).unsqueeze(0) # w 1 1 d\n",
    "            support = support.unsqueeze(2) # w s 1 d\n",
    "            eye = torch.eye(way).unsqueeze(1).unsqueeze(-1).cuda()/shot # w 1 w 1\n",
    "            rescaler = (torch.eye(way)/(shot-1) + torch.ones(way,way)).unsqueeze(1).unsqueeze(-1).cuda()\n",
    "            realc = (centroids - support*eye)*rescaler # w s w d\n",
    "            distmat = torch.sum((realc-support)**2, -1).squeeze().view(-1,way).neg() # ws w\n",
    "        else:\n",
    "            distmat = torch.sum((centroids.unsqueeze(0)-query.unsqueeze(1))**2,2).squeeze().neg()\n",
    "        probs = self.sm(distmat)\n",
    "        return probs\n",
    "    \n",
    "class bPROTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bPROTO, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            Block(3,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            Block(64,64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Block(64,64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.process(inp)\n",
    "        \n",
    "class bPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bPredictor, self).__init__()\n",
    "        self.sm = nn.Softmax(dim=-1)\n",
    "        self.upper = nn.Upsample(size=(84,84), mode='bilinear')\n",
    "        \n",
    "    def forward(self, inp, masks, way, shot):\n",
    "        if self.training:\n",
    "            support = inp.unsqueeze(-1) # B 64 21 21 1\n",
    "            m = masks.unsqueeze(1) # B 1 21 21\n",
    "            c = torch.stack([1-m, m], dim=-1) # B 1 21 21 2     (Positive class corresponds to index/label 1)\n",
    "            c = (c*support).contiguous().view(way,shot,inp.size(1),-1,2).mean(3) # W S 64 2         (Each image's prototypes)\n",
    "            c = (c.sum(1).unsqueeze(1) - c)/(shot-1) # W S 64 2        (Rescaled folded prototypes)\n",
    "            c = c.unsqueeze(3).unsqueeze(3) # W S 64 1 1 2\n",
    "\n",
    "            query = inp.view(way, -1, inp.size(1), inp.size(2), inp.size(3), 1) # W S 64 21 21 1\n",
    "        else:\n",
    "            support = inp[:way*shot].unsqueeze(-1) # B 64 21 21 1\n",
    "            m = masks.unsqueeze(1) # B 1 21 21\n",
    "            c = torch.stack([1-m, m], dim=-1) # B 1 21 21 2     (Positive class corresponds to index/label 1)\n",
    "            c = (c*support).contiguous().view(way,shot,inp.size(1),-1,2).mean(3).mean(1) # W 64 2\n",
    "            c = c.unsqueeze(2).unsqueeze(2).unsqueeze(1) # W 1 64 1 1 2\n",
    "\n",
    "            query = inp[way*trainshot:].view(way, -1, inp.size(1), inp.size(2), inp.size(3), 1) # W S 64 21 21 1\n",
    "        \n",
    "        distmat = ((c-query)**2).sum(2).neg().view(-1, inp.size(2), inp.size(3), 2) # B 21 21 2\n",
    "        probs = self.sm(distmat)[:,:,:,1]\n",
    "        return self.upper(probs.unsqueeze(1))\n",
    "    \n",
    "smodel = [PROTO().cuda() for i in range(esize)]\n",
    "bmodel = bPROTO()\n",
    "bmodel.load_state_dict(torch.load('detectors/saved_models/box_predictors.pth')[0])\n",
    "bmodel.cuda()\n",
    "predictor = Predictor().cuda()\n",
    "bpredictor = bPredictor().cuda()\n",
    "soptimizer = [optim.Adam(m.parameters(), lr=.001) for m in smodel]\n",
    "sscheduler = [optim.lr_scheduler.LambdaLR(o, lambda x: 1/(2**x)) for o in soptimizer]\n",
    "criterion = nn.NLLLoss().cuda()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "nweights = sum([i.numel() for i in list(smodel[0].parameters())])\n",
    "print(nweights,\" parameters in each neural net.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Define the Procedures\n",
    "\n",
    "def train(train_loader, epoch, gpu, vbity):\n",
    "    for model in smodel:\n",
    "        model.train()\n",
    "    bmodel.train()\n",
    "    predictor.train()\n",
    "    bpredictor.train()\n",
    "    targ = Variable(torch.LongTensor([i//foldshot for i in range(foldshot*way)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = [0]*esize\n",
    "    for i, ((inp, m), _) in enumerate(train_loader):\n",
    "        inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "        m = Variable(m).cuda(device = gpu, async=True)\n",
    "        with torch.no_grad():\n",
    "            masks = bpredictor(bmodel(inp), m, way, foldshot).detach()\n",
    "        inp = torch.cat([inp, masks], dim=1)\n",
    "        \n",
    "        for j in range(esize):\n",
    "            smodel[j].zero_grad()\n",
    "            out = predictor(smodel[j](inp), None, way)\n",
    "            loss = criterion(out, targ)\n",
    "            loss.backward()\n",
    "            soptimizer[j].step()\n",
    "        \n",
    "            allloss[j] += loss.item()\n",
    "            \n",
    "        if i%vbity == 0:\n",
    "            print('%d of approx. 192270'%(i*way*(foldshot)))\n",
    "    return [L/i for L in allloss]\n",
    "\n",
    "def validate(val_loader, gpu, vbity, reps, verbose):\n",
    "    for model in smodel:\n",
    "        model.eval()\n",
    "    bmodel.eval()\n",
    "    predictor.eval()\n",
    "    bpredictor.eval()\n",
    "    targ = Variable(torch.LongTensor([i//testshot for i in range(testshot*evalway)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "    allloss = [0]*esize\n",
    "    acctracker = [[] for _ in range(esize)]\n",
    "    for r in range(reps):\n",
    "        for i, ((inp, m), _) in enumerate(val_loader):\n",
    "            inp = Variable(inp).cuda(device = gpu, async=True)\n",
    "            m = Variable(m[evalway*trainshot:]).cuda(device = gpu, async=True)\n",
    "            with torch.no_grad():\n",
    "                masks = bpredictor(bmodel(inp), m, evalway, trainshot).detach()\n",
    "            inp = torch.cat([inp[evalway*trainshot:], masks], dim=1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for j in range(esize):\n",
    "                    out = predictor(smodel[j](inp[:evalway*trainshot]), smodel[j](inp[evalway*trainshot:]), evalway)\n",
    "                    loss = criterion(out, targ)\n",
    "                    allloss[j] += loss.item()\n",
    "                    _,bins = torch.max(out,1)\n",
    "                    acc = torch.sum(torch.eq(bins,targ)).item()/testshot/evalway\n",
    "                    acctracker[j].append(acc)\n",
    "            if i%vbity == 0 and verbose:\n",
    "                print('Round %d of %d, %d of approx. 51716'%(r+1, reps, i*evalway*(trainshot+testshot)))\n",
    "    return [L/i for L in allloss], [np.mean(a) for a in acctracker], [1.96*np.sqrt(np.var(a)/len(a)) for a in acctracker]\n",
    "\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                             RETRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained models\n",
    "\n",
    "ts,m,o = torch.load('saved_models/retraining_folded_initial.torch')\n",
    "for i in range(esize):\n",
    "    smodel[i].load_state_dict(m[i])\n",
    "    soptimizer[i].load_state_dict(o[i])\n",
    "trainlosses, testlosses, acctracker = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/dww78/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of approx. 192270\n",
      "3600 of approx. 192270\n",
      "7200 of approx. 192270\n",
      "10800 of approx. 192270\n",
      "14400 of approx. 192270\n",
      "18000 of approx. 192270\n",
      "21600 of approx. 192270\n",
      "25200 of approx. 192270\n",
      "28800 of approx. 192270\n",
      "32400 of approx. 192270\n",
      "36000 of approx. 192270\n",
      "39600 of approx. 192270\n",
      "43200 of approx. 192270\n",
      "46800 of approx. 192270\n",
      "50400 of approx. 192270\n",
      "54000 of approx. 192270\n",
      "57600 of approx. 192270\n",
      "61200 of approx. 192270\n",
      "64800 of approx. 192270\n",
      "68400 of approx. 192270\n",
      "72000 of approx. 192270\n",
      "75600 of approx. 192270\n",
      "79200 of approx. 192270\n",
      "82800 of approx. 192270\n",
      "86400 of approx. 192270\n",
      "90000 of approx. 192270\n",
      "93600 of approx. 192270\n",
      "97200 of approx. 192270\n",
      "100800 of approx. 192270\n",
      "104400 of approx. 192270\n",
      "108000 of approx. 192270\n",
      "111600 of approx. 192270\n",
      "115200 of approx. 192270\n",
      "118800 of approx. 192270\n",
      "122400 of approx. 192270\n",
      "126000 of approx. 192270\n",
      "129600 of approx. 192270\n",
      "133200 of approx. 192270\n",
      "136800 of approx. 192270\n",
      "140400 of approx. 192270\n",
      "144000 of approx. 192270\n",
      "147600 of approx. 192270\n",
      "151200 of approx. 192270\n",
      "154800 of approx. 192270\n",
      "158400 of approx. 192270\n",
      "162000 of approx. 192270\n",
      "165600 of approx. 192270\n",
      "169200 of approx. 192270\n",
      "172800 of approx. 192270\n",
      "176400 of approx. 192270\n",
      "180000 of approx. 192270\n",
      "183600 of approx. 192270\n",
      "187200 of approx. 192270\n",
      "190800 of approx. 192270\n",
      "194400 of approx. 192270\n",
      "Round 1 of 1, 0 of approx. 51716\n",
      "Round 1 of 1, 1500 of approx. 51716\n",
      "Round 1 of 1, 3000 of approx. 51716\n",
      "Round 1 of 1, 4500 of approx. 51716\n",
      "Round 1 of 1, 6000 of approx. 51716\n",
      "Round 1 of 1, 7500 of approx. 51716\n",
      "Round 1 of 1, 9000 of approx. 51716\n",
      "Round 1 of 1, 10500 of approx. 51716\n",
      "Round 1 of 1, 12000 of approx. 51716\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-985f9987201c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate, single pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtestloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvbity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# update the precision graph, report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-69616e1b7641>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, gpu, vbity, reps, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0macctracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevalway\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrainshot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_put_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8e324651da30>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                     \u001b[0midlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtrainshot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtestshot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mtrackdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# Do the Thing!\n",
    "\n",
    "start = time.time()\n",
    "# trainlosses, testlosses, acctracker = [[] for _ in range(esize)],[[] for _ in range(esize)],[[] for _ in range(esize)]\n",
    "epochs = 5*epoch\n",
    "for e in range(epochs):\n",
    "    # Adjust learnrate\n",
    "    if e%epoch == 0:\n",
    "        [s.step() for s in sscheduler]\n",
    "    \n",
    "    # Train for one epoch\n",
    "    trainloss = train(train_loader, e, gpu, vbity)\n",
    "    \n",
    "    # Evaluate, single pass\n",
    "    testloss, acc, _ = validate(test_loader, gpu, vbity, 1, True)\n",
    "    \n",
    "    # update the precision graph, report\n",
    "    display.clear_output(wait=True)\n",
    "    for j in range(esize):\n",
    "        trainlosses[j].append(trainloss[j])\n",
    "        testlosses[j].append(testloss[j])\n",
    "        acctracker[j].append(acc[j])\n",
    "    pl.figure(1, figsize=(15,15))\n",
    "    for i in range(esize):\n",
    "        pl.subplot(esize,2,2*i+1)\n",
    "        pl.plot(trainlosses[i])\n",
    "        pl.plot(testlosses[i])\n",
    "        pl.axvline(x=49)\n",
    "        pl.ylim((0.5,3))\n",
    "        pl.title(\"Loss: Training Blue, Validation Gold\")\n",
    "        pl.subplot(esize,2,2*i+2)\n",
    "        pl.plot(acctracker[i][::-1])\n",
    "        pl.axvline(x=len(trainlosses[i])-50)\n",
    "        pl.ylim((0.4,.9))\n",
    "        pl.title(\"Validation Acc\")\n",
    "    pl.show()\n",
    "    print(\"Train loss is: \"+str(trainloss)+\n",
    "            \"\\nValidation accuracy is: \"+str(acc)+\n",
    "            \"\\nValidation loss is: \"+str(testloss)+\"\\n\")\n",
    "    \n",
    "    print(\"%.2f hours to completion\"%(  (time.time()-start)/(e+1)*(epochs-e)/3600  ))\n",
    "    print()\n",
    "print((time.time()-start)/3600, \"hours total\") \n",
    "_, score, conf = validate(test_loader, gpu, vbity, 10, False)\n",
    "for i in range(esize):\n",
    "    print('Model %d final score: %.2f +- %.2f'%(i, score[i]*100, conf[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix this code, save models\n",
    "\n",
    "torch.save(((trainlosses, testlosses, acctracker), \n",
    "            tuple([m.state_dict() for m in smodel]),  \n",
    "            tuple([m.state_dict() for m in qmodel]),\n",
    "           ), 'saved_models/retraining_folded_final.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.sm = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, support, query, way):\n",
    "        assert support.size(0)%way == 0,\"Error: classes are not the same size!\"\n",
    "        shot = support.size(0)//way\n",
    "        support = support.view(way,shot,-1)\n",
    "        centroids = torch.mean(support, 1).view(support.size(0),-1)\n",
    "        if self.training:\n",
    "            centroids = centroids.unsqueeze(0).unsqueeze(0) # w 1 1 d\n",
    "            support = support.unsqueeze(2) # w s 1 d\n",
    "            eye = torch.eye(way).unsqueeze(1).unsqueeze(-1).cuda()/shot # w 1 w 1\n",
    "            realc = centroids - support*eye # w s w d\n",
    "            query = query.view(way,shot,-1).unsqueeze(2) # as support\n",
    "            distmat = torch.sum((realc-query)**2, -1).squeeze().view(-1,way).neg()\n",
    "        else:\n",
    "            distmat = torch.sum((centroids.unsqueeze(0)-query.unsqueeze(1))**2,2).squeeze().neg()\n",
    "        probs = self.sm(distmat)\n",
    "        return probs, realc\n",
    "    \n",
    "predictor = Predictor().cuda()\n",
    "\n",
    "targ = Variable(torch.LongTensor([i//foldshot for i in range(foldshot*way)])).cuda(\n",
    "        device = gpu, async=True)\n",
    "for i, (inp, _) in enumerate(train_loader):\n",
    "    inp = Variable(inp, requires_grad=False).cuda(device = gpu, async=True)\n",
    "    sout = smodel[0](inp)\n",
    "    qout = qmodel[0](inp)\n",
    "    out, cs = predictor(sout, qout, way)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0586,  1.0457,  2.5906,  3.0103,  4.6438,  3.4559,  2.1381,\n",
       "         2.8018,  3.3086,  2.9854,  2.2302,  2.2749,  3.0698,  2.8040,\n",
       "         2.5778,  2.1802,  2.4214,  1.8347,  1.0344,  1.5382], device='cuda:1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtest = qout.view(way,-1,1,64)\n",
    "dists = ((cs-qtest)**2).sum(-1).view(-1,way)\n",
    "dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1414,  0.1432,  0.0305,  0.0201,  0.0039,  0.0129,  0.0480,\n",
       "         0.0247,  0.0149,  0.0206,  0.0438,  0.0419,  0.0189,  0.0247,\n",
       "         0.0309,  0.0460,  0.0362,  0.0651,  0.1448,  0.0875], device='cuda:1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=-1)(dists.neg())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0216, -0.0767,  0.0753, -0.1175, -0.0373,  0.2071,  0.0953,\n",
      "         0.0033,  0.0900,  0.0187,  0.0580, -0.1866, -0.0502,  0.0504,\n",
      "        -0.0713,  0.1276,  0.0027, -0.1834, -0.0068, -0.0655,  0.0087,\n",
      "        -0.1566,  0.2866, -0.0178,  0.0170, -0.0816,  0.0360, -0.0235,\n",
      "        -0.0124, -0.0026, -0.0084, -0.0087, -0.1775,  0.0063,  0.0058,\n",
      "         0.0132,  0.0188,  0.0041,  0.1041,  0.0000,  0.0210,  0.1115,\n",
      "        -0.0414,  0.0952,  0.0010,  0.0477,  0.0180, -0.1303, -0.2335,\n",
      "         0.0008,  0.0233,  0.0042,  0.0868,  0.0047, -0.0032, -0.0020,\n",
      "         0.0687, -0.0172,  0.2589, -0.0195,  0.1050,  0.0364,  0.0091,\n",
      "         0.0243], device='cuda:1')\n",
      "tensor([-0.0119,  0.1042,  0.0543,  0.0286, -0.0113,  0.4196,  0.0554,\n",
      "         0.0189,  0.0442,  0.0526,  0.1375, -0.2443, -0.1407,  0.1472,\n",
      "        -0.1517,  0.2828,  0.0044,  0.2813, -0.0161, -0.0372, -0.0852,\n",
      "        -0.2883,  0.2878, -0.0016,  0.2680, -0.1410, -0.1184, -0.0955,\n",
      "         0.0049, -0.0033,  0.0037,  0.1340, -0.4401,  0.0108,  0.0007,\n",
      "        -0.0002, -0.0288,  0.1592,  0.2284,  0.0000, -0.1592, -0.1726,\n",
      "         0.0052, -0.0606,  0.0010,  0.1032,  0.0312,  0.1971, -0.2376,\n",
      "         0.0011,  0.0072,  0.0953,  0.2159, -0.0010, -0.0267, -0.0286,\n",
      "         0.2322, -0.0095,  0.5954, -0.0396,  0.0249,  0.0665,  0.0256,\n",
      "         0.0311], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(cs[0,0,0])\n",
    "print(qout[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion(out, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3617, device='cuda:2')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(((trainlosses, testlosses, acctracker), \n",
    "            [m.state_dict() for m in smodel], \n",
    "            [m.state_dict() for m in qmodel]\n",
    "           ), 'saved_models/retraining_folded_final.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First run: 73.26 +- .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
